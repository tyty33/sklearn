# 数据无量纲化

数据无量纲化：将不同规格的数据转换到同一规格，或不同分布的数据转换到某个特定分布
的需求，这种需求统称为将数据“无量纲化”。

譬如梯度和矩阵为核心的算法中，譬如逻辑回归，支持向量机，神经网络，无量纲化可以加快求解速度；而在距离类模型，譬如K近邻，K-Means聚类中，无量纲化可以帮我们提升模型精度，避免某一个取值范围特别大的特征对距离计算造成影响。（一个特例是决策树和树的集成算法们，对决策树我们不需要无量纲化，决策树可以把任意数据都处理得很好。）

数据的无量纲化可以是线性的，也可以是非线性的。线性的无量纲化包括中心化（Zero-centered或者Mean-subtraction）处理和缩放处理（Scale）。中心化的本质是让所有记录减去一个固定值，即让数据样本数据平移到某个位置。缩放的本质是通过除以一个固定值，将数据固定在某个范围之中，取对数也算是一种缩放处理。

1. preprocessing.MinMaxScaler：数据归一化

当数据(x)按照最小值中心化后，再按极差（最大值 - 最小值）缩放，数据移动了最小值个单位，并且会被收敛到[0,1]之间，而这个过程，就叫做数据归一化(Normalization，又称Min-Max Scaling)。

```python
from sklearn.preprocessing import MinMaxScaler
import pandas as pd

data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]
data = pd.DataFrame(data)
print(data)
#
# # 实现归一化
scaler = MinMaxScaler() #实例化
scaler = scaler.fit(data) #fit，在这里本质是生成min(x)和max(x)
result = scaler.transform(data)
print(result)

scaler = MinMaxScaler()  # 实例化
result_ = scaler.fit_transform(data)  # 训练和导出结果一步达成
print(result_)

# origin = scaler.inverse_transform(result_)  # 将归一化后的结果逆转
# print(origin)

# 使用MinMaxScaler的参数feature_range实现将数据归一化到[0,1]以外的范围中
# data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]
# scaler = MinMaxScaler(feature_range=[5, 10])  # 依然实例化
# result_n = scaler.fit_transform(data)  # fit_transform一步导出结果
# print(result_n)

# 当X中的特征数量非常多的时候，fit会报错并表示，数据量太大了我计算不了
# 此时使用partial_fit作为训练接口
# scaler = scaler.partial_fit(data)
```

1. preprocessing.StandardScaler：数据标准化

当数据(x)按均值(μ)中心化后，再按标准差(σ)缩放，数据就会服从为均值为0，方差为1的正态分布（即标准正态分布），而这个过程，就叫做数据标准化(Standardization，又称Z-score normalization)。

```python
from sklearn.preprocessing import StandardScaler

data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]

scaler = StandardScaler()  # 实例化
scaler.fit(data)  # fit，本质是生成均值和方差

print(scaler.mean_)  # 查看均值的属性mean_
print(scaler.var_)  # 查看方差的属性var_

x_std = scaler.transform(data)  # 通过接口导出结果

print(x_std.mean())  # 导出的结果是一个数组，用mean()查看均值
print(x_std.std())  # 用std()查看方差

result = scaler.fit_transform(data)  # 使用fit_transform(data)一步达成结果
print(result)
origin = scaler.inverse_transform(x_std)  # 使用inverse_transform逆转标准化
print(origin)
```

StandardScaler和MinMaxScaler的选择

大多数机器学习算法中，会选择StandardScaler来进行特征缩放，因为MinMaxScaler对异常值非常敏感。在PCA，聚类，逻辑回归，支持向量机，神经网络这些算法中，StandardScaler往往是最好的选择。

MinMaxScaler在不涉及距离度量、梯度、协方差计算以及数据需要被压缩到特定区间时使用广泛，比如数字图像处理中量化像素强度时，都会使用MinMaxScaler将数据压缩于[0,1]区间之中。

建议先试试看StandardScaler，效果不好换MinMaxScaler。

![Untitled](%E6%95%B0%E6%8D%AE%E6%97%A0%E9%87%8F%E7%BA%B2%E5%8C%96%20e6106/Untitled.png)